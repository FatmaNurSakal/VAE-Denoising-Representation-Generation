{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    import umap \nexcept:\n    !pip -q install umap-learn\n\nimport os, struct, csv, math, time\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\nprint(\"TensorFlow:\", tf.__version__)\n\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ngpus = tf.config.list_physical_devices(\"GPU\")\nprint(\"GPUs:\", gpus)\n\ntry:\n    tf.config.optimizer.set_jit(True)\n    print(\"XLA: enabled\")\nexcept Exception as e:\n    print(\"XLA enable failed:\", e)\n\nUSE_MIXED = len(gpus) > 0\ntry:\n    from tensorflow.keras import mixed_precision\n    if USE_MIXED:\n        mixed_precision.set_global_policy(\"mixed_float16\")\n        print(\"Mixed precision:\", mixed_precision.global_policy())\n    else:\n        mixed_precision.set_global_policy(\"float32\")\n        print(\"Mixed precision: disabled (no GPU) ->\", mixed_precision.global_policy())\nexcept Exception as e:\n    print(\"Mixed precision set failed:\", e)\n\nDATA_DIR = \"/kaggle/input/fashionmnist\"\nOUT_DIR = \"/kaggle/working/vae_outputs_v3\"\nos.makedirs(OUT_DIR, exist_ok=True)\nprint(\"Outputs will be saved to:\", OUT_DIR)\n\ndef savefig(path, dpi=200):\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    print(\"Saved:\", path)\n\ndef load_idx_images(path):\n    with open(path, \"rb\") as f:\n        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        if magic != 2051:\n            raise ValueError(f\"Invalid magic number {magic} in {path}\")\n        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n    return images\n\ndef load_idx_labels(path):\n    with open(path, \"rb\") as f:\n        magic, num = struct.unpack(\">II\", f.read(8))\n        if magic != 2049:\n            raise ValueError(f\"Invalid magic number {magic} in {path}\")\n        labels = np.frombuffer(f.read(), dtype=np.uint8)\n    return labels\n\ntrain_images_path = os.path.join(DATA_DIR, \"train-images-idx3-ubyte\")\ntrain_labels_path = os.path.join(DATA_DIR, \"train-labels-idx1-ubyte\")\ntest_images_path  = os.path.join(DATA_DIR, \"t10k-images-idx3-ubyte\")\ntest_labels_path  = os.path.join(DATA_DIR, \"t10k-labels-idx1-ubyte\")\n\nx_train = load_idx_images(train_images_path)\ny_train = load_idx_labels(train_labels_path)\nx_test  = load_idx_images(test_images_path)\ny_test  = load_idx_labels(test_labels_path)\n\nx_train = (x_train.astype(\"float32\") / 255.0)[..., None]\nx_test  = (x_test.astype(\"float32\")  / 255.0)[..., None]\n\nprint(\"Train:\", x_train.shape, y_train.shape)\nprint(\"Test :\", x_test.shape, y_test.shape)\n\ndef add_gaussian_noise(x, noise_factor=0.45):\n    noise = tf.random.normal(tf.shape(x), mean=0.0, stddev=1.0, seed=SEED, dtype=tf.float32)\n    x = tf.convert_to_tensor(x, dtype=tf.float32)\n    x_noisy = tf.clip_by_value(x + noise_factor * noise, 0.0, 1.0)\n    return x_noisy\n\nNOISE_FACTOR = 0.45\nx_train_noisy = add_gaussian_noise(x_train, NOISE_FACTOR)\nx_test_noisy  = add_gaussian_noise(x_test,  NOISE_FACTOR)\n\nBATCH_SIZE = 256\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = (\n    tf.data.Dataset.from_tensor_slices((x_train_noisy, x_train, y_train))\n    .shuffle(20000, seed=SEED)\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .cache()\n    .prefetch(AUTOTUNE)\n)\n\ntest_ds = (\n    tf.data.Dataset.from_tensor_slices((x_test_noisy, x_test, y_test))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTOTUNE)\n)\n\nLATENT_DIM = 16\n\nclass Sampling(layers.Layer):\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        dtype = z_mean.dtype\n        eps = tf.random.normal(tf.shape(z_mean), seed=SEED, dtype=dtype)\n        return z_mean + tf.exp(0.5 * z_log_var) * eps\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0]\n\ndef conv_block(x, filters, k=3, s=1):\n    x = layers.Conv2D(filters, k, strides=s, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    return x\n\ndef deconv_block(x, filters, k=3, s=2):\n    x = layers.Conv2DTranspose(filters, k, strides=s, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    return x\n\ndef build_encoder(latent_dim=LATENT_DIM):\n    inp = keras.Input(shape=(28, 28, 1), name=\"encoder_input\")\n    x = conv_block(inp, 32, 3, 2)   # 14x14\n    x = conv_block(x, 64, 3, 2)     # 7x7\n    x = conv_block(x, 128, 3, 1)\n    x = layers.Flatten()(x)\n    x = layers.Dense(256)(x)\n    x = layers.LeakyReLU()(x)\n    x = layers.Dropout(0.1)(x)\n\n    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n    z = Sampling(name=\"sampling\")([z_mean, z_log_var])\n    return keras.Model(inp, [z_mean, z_log_var, z], name=\"encoder\")\n\ndef build_decoder(latent_dim=LATENT_DIM):\n    inp = keras.Input(shape=(latent_dim,), name=\"decoder_input\")\n    x = layers.Dense(7 * 7 * 128)(inp)\n    x = layers.LeakyReLU()(x)\n    x = layers.Reshape((7, 7, 128))(x)\n    x = deconv_block(x, 64, 3, 2)   # 14x14\n    x = deconv_block(x, 32, 3, 2)   # 28x28\n    x = layers.Conv2D(16, 3, padding=\"same\")(x)\n    x = layers.LeakyReLU()(x)\n\n    out = layers.Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\", dtype=\"float32\")(x)\n    return keras.Model(inp, out, name=\"decoder\")\n\nencoder = build_encoder(LATENT_DIM)\ndecoder = build_decoder(LATENT_DIM)\n\nencoder.summary()\ndecoder.summary()\n\n@tf.function\ndef recon_loss_bce(x_true, x_pred):\n    bce = keras.backend.binary_crossentropy(x_true, x_pred)  # (B,28,28)\n    return tf.reduce_mean(tf.reduce_sum(bce, axis=[1, 2]))\n\n@tf.function\ndef kl_divergence(z_mean, z_log_var):\n    z_mean = tf.cast(z_mean, tf.float32)\n    z_log_var = tf.cast(z_log_var, tf.float32)\n    return -0.5 * tf.reduce_mean(tf.reduce_sum(\n        1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n    ))\n\n@tf.function\ndef supervised_contrastive_loss(z, y, temperature=0.2):\n    \"\"\"\n    z: (B, D) latent mean\n    y: (B,) int labels\n    \"\"\"\n    z = tf.cast(z, tf.float32)\n    z = tf.math.l2_normalize(z, axis=1)\n\n    y = tf.cast(y, tf.int32)\n    y = tf.reshape(y, [-1, 1])\n    mask = tf.cast(tf.equal(y, tf.transpose(y)), tf.float32)  # (B,B)\n\n    logits = tf.matmul(z, z, transpose_b=True) / temperature\n\n    bsz = tf.shape(z)[0]\n    logits_mask = tf.ones_like(mask) - tf.eye(bsz)\n    mask = mask * logits_mask\n\n    logits = logits - tf.reduce_max(logits, axis=1, keepdims=True)\n    exp_logits = tf.exp(logits) * logits_mask\n    log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True) + 1e-12)\n\n    mean_log_prob_pos = tf.reduce_sum(mask * log_prob, axis=1) / (tf.reduce_sum(mask, axis=1) + 1e-12)\n    return -tf.reduce_mean(mean_log_prob_pos)\n\nclass BetaWarmup(keras.callbacks.Callback):\n    def __init__(self, beta_max=1.0, warmup_epochs=8):\n        super().__init__()\n        self.beta_max = beta_max\n        self.warmup_epochs = warmup_epochs\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if epoch < self.warmup_epochs:\n            beta = self.beta_max * (epoch + 1) / self.warmup_epochs\n        else:\n            beta = self.beta_max\n        self.model.beta.assign(beta)\n\nclass VAE(keras.Model):\n    def __init__(self, encoder, decoder, beta_max=1.0, gamma_sc=1.0, **kwargs):\n        super().__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.beta = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n        self.beta_max = beta_max\n        self.gamma_sc = tf.Variable(gamma_sc, trainable=False, dtype=tf.float32)\n\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.recon_loss_tracker = keras.metrics.Mean(name=\"recon_loss\")\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        self.sc_loss_tracker = keras.metrics.Mean(name=\"supcon_loss\")\n\n    @property\n    def metrics(self):\n        return [self.total_loss_tracker, self.recon_loss_tracker, self.kl_loss_tracker, self.sc_loss_tracker]\n\n    def train_step(self, data):\n        x_noisy, x_clean, y = data\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(x_noisy, training=True)\n            x_recon = self.decoder(z, training=True)\n\n            r_loss = recon_loss_bce(x_clean, x_recon)\n            k_loss = kl_divergence(z_mean, z_log_var)\n            sc_loss = supervised_contrastive_loss(z_mean, y, temperature=0.2)\n\n            total = r_loss + self.beta * k_loss + self.gamma_sc * sc_loss\n\n        grads = tape.gradient(total, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n\n        self.total_loss_tracker.update_state(total)\n        self.recon_loss_tracker.update_state(r_loss)\n        self.kl_loss_tracker.update_state(k_loss)\n        self.sc_loss_tracker.update_state(sc_loss)\n\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"recon_loss\": self.recon_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n            \"supcon_loss\": self.sc_loss_tracker.result(),\n            \"beta\": self.beta,\n            \"gamma_sc\": self.gamma_sc\n        }\n\n    def test_step(self, data):\n        x_noisy, x_clean, y = data\n        z_mean, z_log_var, z = self.encoder(x_noisy, training=False)\n        x_recon = self.decoder(z, training=False)\n\n        r_loss = recon_loss_bce(x_clean, x_recon)\n        k_loss = kl_divergence(z_mean, z_log_var)\n        sc_loss = supervised_contrastive_loss(z_mean, y, temperature=0.2)\n\n        total = r_loss + self.beta * k_loss + self.gamma_sc * sc_loss\n\n        self.total_loss_tracker.update_state(total)\n        self.recon_loss_tracker.update_state(r_loss)\n        self.kl_loss_tracker.update_state(k_loss)\n        self.sc_loss_tracker.update_state(sc_loss)\n\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"recon_loss\": self.recon_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n            \"supcon_loss\": self.sc_loss_tracker.result(),\n            \"beta\": self.beta,\n            \"gamma_sc\": self.gamma_sc\n        }\n\nEPOCHS = 20\nGAMMA_SC = 1.0      \nBETA_MAX = 1.0\nWARMUP_EPOCHS = 8\n\nvae = VAE(encoder, decoder, beta_max=BETA_MAX, gamma_sc=GAMMA_SC)\nvae.compile(optimizer=keras.optimizers.Adam(1e-3))\n\ncallbacks = [\n    BetaWarmup(beta_max=BETA_MAX, warmup_epochs=WARMUP_EPOCHS),\n    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1),\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1),\n]\n\nt0 = time.time()\nhistory = vae.fit(\n    train_ds,\n    validation_data=test_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    verbose=1\n)\nprint(\"Training time (s):\", round(time.time() - t0, 2))\n\ndef plot_history(hist):\n    h = hist.history\n    def safe_get(k): return h[k] if k in h else []\n    epochs = np.arange(1, len(safe_get(\"loss\")) + 1)\n\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs, safe_get(\"loss\"), label=\"train_loss\")\n    if len(safe_get(\"val_loss\")): plt.plot(epochs, safe_get(\"val_loss\"), label=\"val_loss\")\n    plt.title(\"Training Curve - Total Loss\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n    savefig(os.path.join(OUT_DIR, \"01_train_total_loss.png\"))\n    plt.show()\n\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs, safe_get(\"recon_loss\"), label=\"train_recon\")\n    if len(safe_get(\"val_recon_loss\")): plt.plot(epochs, safe_get(\"val_recon_loss\"), label=\"val_recon\")\n    plt.title(\"Training Curve - Recon Loss\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"Recon\"); plt.legend()\n    savefig(os.path.join(OUT_DIR, \"02_train_recon_loss.png\"))\n    plt.show()\n\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs, safe_get(\"kl_loss\"), label=\"train_kl\")\n    if len(safe_get(\"val_kl_loss\")): plt.plot(epochs, safe_get(\"val_kl_loss\"), label=\"val_kl\")\n    plt.title(\"Training Curve - KL Loss\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"KL\"); plt.legend()\n    savefig(os.path.join(OUT_DIR, \"03_train_kl_loss.png\"))\n    plt.show()\n\n    plt.figure(figsize=(7,4))\n    plt.plot(epochs, safe_get(\"supcon_loss\"), label=\"train_supcon\")\n    if len(safe_get(\"val_supcon_loss\")): plt.plot(epochs, safe_get(\"val_supcon_loss\"), label=\"val_supcon\")\n    plt.title(\"Training Curve - SupCon Loss (Latent Separation)\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"SupCon\"); plt.legend()\n    savefig(os.path.join(OUT_DIR, \"03B_train_supcon_loss.png\"))\n    plt.show()\n\n    if \"beta\" in h:\n        plt.figure(figsize=(7,3.5))\n        plt.plot(epochs, safe_get(\"beta\"), label=\"beta\")\n        plt.title(\"KL Weight (Beta) Warmup\")\n        plt.xlabel(\"Epoch\"); plt.ylabel(\"Beta\"); plt.legend()\n        savefig(os.path.join(OUT_DIR, \"04_beta_warmup.png\"))\n        plt.show()\n\nplot_history(history)\n\nhist_csv = os.path.join(OUT_DIR, \"history.csv\")\nwith open(hist_csv, \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    keys = list(history.history.keys())\n    writer.writerow([\"epoch\"] + keys)\n    for i in range(len(history.history[keys[0]])):\n        writer.writerow([i+1] + [history.history[k][i] for k in keys])\nprint(\"Saved:\", hist_csv)\n\ndef show_denoising_examples(n=10, seed=SEED, fname=\"05_denoising_grid.png\"):\n    rng = np.random.default_rng(seed)\n    idx = rng.choice(len(x_test), size=n, replace=False)\n\n    xN = tf.gather(x_test_noisy, idx)\n    xC = tf.gather(x_test, idx)\n\n    z_mean, z_log_var, z = encoder(xN, training=False)\n    xR = decoder(z, training=False)\n\n    plt.figure(figsize=(n*1.8, 5))\n    for i in range(n):\n        ax = plt.subplot(3, n, i+1)\n        plt.imshow(xN[i, :, :, 0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: ax.set_title(\"Noisy\")\n\n        ax = plt.subplot(3, n, i+1+n)\n        plt.imshow(xR[i, :, :, 0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: ax.set_title(\"VAE Recon\")\n\n        ax = plt.subplot(3, n, i+1+2*n)\n        plt.imshow(xC[i, :, :, 0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: ax.set_title(\"Clean\")\n\n    plt.suptitle(\"VAE Denoising (Fashion-MNIST)\", y=1.02, fontsize=16)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\nshow_denoising_examples(10)\n\ndef mse(a, b):\n    a = tf.cast(a, tf.float32); b = tf.cast(b, tf.float32)\n    return tf.reduce_mean(tf.square(a - b))\n\ndef mean_psnr(a, b):\n    a = tf.cast(a, tf.float32); b = tf.cast(b, tf.float32)\n    return tf.reduce_mean(tf.image.psnr(a, b, max_val=1.0))\n\ndef mean_ssim(a, b):\n    a = tf.cast(a, tf.float32); b = tf.cast(b, tf.float32)\n    return tf.reduce_mean(tf.image.ssim(a, b, max_val=1.0))\n\nall_noisy = x_test_noisy\nall_clean = x_test\n\nz_mean_all, z_log_var_all, z_all = encoder(all_noisy, training=False)\nall_recon = decoder(z_all, training=False)\n\nmse_noisy = float(mse(all_noisy, all_clean).numpy())\nmse_vae   = float(mse(all_recon, all_clean).numpy())\n\npsnr_noisy = float(mean_psnr(all_noisy, all_clean).numpy())\npsnr_vae   = float(mean_psnr(all_recon, all_clean).numpy())\n\nssim_noisy = float(mean_ssim(all_noisy, all_clean).numpy())\nssim_vae   = float(mean_ssim(all_recon, all_clean).numpy())\n\nmse_improve_pct = (mse_noisy - mse_vae) / (mse_noisy + 1e-12) * 100.0\npsnr_gain = psnr_vae - psnr_noisy\nssim_gain = ssim_vae - ssim_noisy\n\nprint(\"\\n=== Denoising Metrics (Test) ===\")\nprint(f\"NOISE_FACTOR={NOISE_FACTOR} | LATENT_DIM={LATENT_DIM} | BATCH={BATCH_SIZE} | EPOCHS={EPOCHS}\")\nprint(f\"Baseline (Noisy->Clean)  MSE={mse_noisy:.6f} | PSNR={psnr_noisy:.3f} dB | SSIM={ssim_noisy:.4f}\")\nprint(f\"VAE (Recon->Clean)       MSE={mse_vae:.6f} | PSNR={psnr_vae:.3f} dB | SSIM={ssim_vae:.4f}\")\nprint(\"\\n=== Improvement (Higher is better) ===\")\nprint(f\"MSE improvement: {mse_improve_pct:.2f}% (↓)\")\nprint(f\"PSNR gain      : {psnr_gain:.3f} dB (↑)\")\nprint(f\"SSIM gain      : {ssim_gain:.4f} (↑)\")\n\nmetrics_txt = os.path.join(OUT_DIR, \"metrics.txt\")\nwith open(metrics_txt, \"w\") as f:\n    f.write(\"=== Denoising Metrics (Test) ===\\n\")\n    f.write(f\"NOISE_FACTOR={NOISE_FACTOR}\\nLATENT_DIM={LATENT_DIM}\\nBATCH_SIZE={BATCH_SIZE}\\nEPOCHS={EPOCHS}\\n\\n\")\n    f.write(f\"Baseline (Noisy->Clean)  MSE={mse_noisy:.6f} | PSNR={psnr_noisy:.3f} dB | SSIM={ssim_noisy:.4f}\\n\")\n    f.write(f\"VAE (Recon->Clean)       MSE={mse_vae:.6f} | PSNR={psnr_vae:.3f} dB | SSIM={ssim_vae:.4f}\\n\\n\")\n    f.write(\"=== Improvement ===\\n\")\n    f.write(f\"MSE improvement: {mse_improve_pct:.2f}%\\n\")\n    f.write(f\"PSNR gain      : {psnr_gain:.3f} dB\\n\")\n    f.write(f\"SSIM gain      : {ssim_gain:.4f}\\n\")\nprint(\"Saved:\", metrics_txt)\n\nmetrics_csv = os.path.join(OUT_DIR, \"metrics.csv\")\nwith open(metrics_csv, \"w\", newline=\"\") as f:\n    w = csv.writer(f)\n    w.writerow([\"metric\", \"baseline_noisy_to_clean\", \"vae_recon_to_clean\", \"delta_or_improvement\"])\n    w.writerow([\"MSE\",  mse_noisy,  mse_vae,  mse_improve_pct])\n    w.writerow([\"PSNR_dB\", psnr_noisy, psnr_vae, psnr_gain])\n    w.writerow([\"SSIM\", ssim_noisy, ssim_vae, ssim_gain])\nprint(\"Saved:\", metrics_csv)\n\nFASHION_LABELS_TR = {\n    0: \"Tişört / Üst\",\n    1: \"Pantolon\",\n    2: \"Kazak\",\n    3: \"Elbise\",\n    4: \"Mont / Kaban\",\n    5: \"Sandalet\",\n    6: \"Gömlek\",\n    7: \"Spor Ayakkabı\",\n    8: \"Çanta\",\n    9: \"Bot\"\n}\n\ndef plot_latent_pca_tr(N_VIS=8000, use_noisy=True,\n                       fnameA=\"06A_latent_pca_numbers.png\",\n                       fnameB=\"06B_latent_pca_text_tr.png\"):\n    y_vis = y_test[:N_VIS]\n    x_for_latent = x_test_noisy[:N_VIS] if use_noisy else x_test[:N_VIS]\n\n    z_mean_vis, _, _ = encoder(tf.convert_to_tensor(x_for_latent, dtype=tf.float32), training=False)\n    z_mean_vis = z_mean_vis.numpy()\n\n    pca = PCA(n_components=2, random_state=SEED)\n    z2 = pca.fit_transform(z_mean_vis)\n\n    plt.figure(figsize=(9,7))\n    sc = plt.scatter(z2[:,0], z2[:,1], c=y_vis, s=6, alpha=0.25)\n    plt.colorbar(sc, ticks=range(10))\n    plt.title(\"Latent Space (z_mean) - PCA 2D (Label: 0-9)\")\n    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n    savefig(os.path.join(OUT_DIR, fnameA))\n    plt.show()\n\n    plt.figure(figsize=(9,7))\n    sc2 = plt.scatter(z2[:,0], z2[:,1], c=y_vis, s=6, alpha=0.20)\n    cbar2 = plt.colorbar(sc2, ticks=range(10))\n    cbar2.ax.set_yticklabels([f\"{i} - {FASHION_LABELS_TR[i]}\" for i in range(10)])\n    plt.title(\"Latent Space (z_mean) - PCA 2D (Türkçe Sınıf Adları)\")\n    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n\n    for cls in range(10):\n        mask = (y_vis == cls)\n        if np.sum(mask) == 0:\n            continue\n        cx = np.mean(z2[mask, 0]); cy = np.mean(z2[mask, 1])\n        plt.text(cx, cy, f\"{cls}: {FASHION_LABELS_TR[cls]}\",\n                 fontsize=10, fontweight=\"bold\",\n                 ha=\"center\", va=\"center\",\n                 bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"black\", alpha=0.85))\n\n    savefig(os.path.join(OUT_DIR, fnameB))\n    plt.show()\n\n    pca_txt = os.path.join(OUT_DIR, \"pca_explained_variance.txt\")\n    with open(pca_txt, \"w\") as f:\n        f.write(\"PCA Explained Variance Ratio (2 components)\\n\")\n        f.write(str(pca.explained_variance_ratio_) + \"\\n\")\n        f.write(\"Sum: \" + str(np.sum(pca.explained_variance_ratio_)) + \"\\n\")\n    print(\"Saved:\", pca_txt)\n\ndef plot_latent_umap_or_tsne(N_VIS=8000, use_noisy=True,\n                            fname_umap=\"06C_latent_umap_text_tr.png\",\n                            fname_tsne=\"06D_latent_tsne_text_tr.png\"):\n    y_vis = y_test[:N_VIS]\n    x_for_latent = x_test_noisy[:N_VIS] if use_noisy else x_test[:N_VIS]\n\n    z_mean_vis, _, _ = encoder(tf.convert_to_tensor(x_for_latent, dtype=tf.float32), training=False)\n    z_mean_vis = z_mean_vis.numpy()\n\n    try:\n        import umap\n        reducer = umap.UMAP(n_components=2, random_state=SEED, n_neighbors=25, min_dist=0.05)\n        z2 = reducer.fit_transform(z_mean_vis)\n\n        plt.figure(figsize=(9,7))\n        sc = plt.scatter(z2[:,0], z2[:,1], c=y_vis, s=6, alpha=0.35)\n        cbar = plt.colorbar(sc, ticks=range(10))\n        cbar.ax.set_yticklabels([f\"{i} - {FASHION_LABELS_TR[i]}\" for i in range(10)])\n        plt.title(\"Latent Space (z_mean) - UMAP 2D (Türkçe Sınıf Adları)\")\n        plt.xlabel(\"UMAP1\"); plt.ylabel(\"UMAP2\")\n\n        for cls in range(10):\n            m = (y_vis == cls)\n            cx, cy = np.mean(z2[m,0]), np.mean(z2[m,1])\n            plt.text(cx, cy, f\"{cls}: {FASHION_LABELS_TR[cls]}\",\n                     fontsize=10, fontweight=\"bold\",\n                     ha=\"center\", va=\"center\",\n                     bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"black\", alpha=0.85))\n\n        savefig(os.path.join(OUT_DIR, fname_umap))\n        plt.show()\n        return\n    except Exception as e:\n        print(\"UMAP not available -> t-SNE fallback. Reason:\", e)\n\n    tsne = TSNE(n_components=2, perplexity=35, learning_rate=\"auto\", init=\"pca\", random_state=SEED)\n    z2 = tsne.fit_transform(z_mean_vis)\n\n    plt.figure(figsize=(9,7))\n    sc = plt.scatter(z2[:,0], z2[:,1], c=y_vis, s=6, alpha=0.35)\n    cbar = plt.colorbar(sc, ticks=range(10))\n    cbar.ax.set_yticklabels([f\"{i} - {FASHION_LABELS_TR[i]}\" for i in range(10)])\n    plt.title(\"Latent Space (z_mean) - t-SNE 2D (Türkçe Sınıf Adları)\")\n    plt.xlabel(\"tSNE1\"); plt.ylabel(\"tSNE2\")\n\n    for cls in range(10):\n        m = (y_vis == cls)\n        cx, cy = np.mean(z2[m,0]), np.mean(z2[m,1])\n        plt.text(cx, cy, f\"{cls}: {FASHION_LABELS_TR[cls]}\",\n                 fontsize=10, fontweight=\"bold\",\n                 ha=\"center\", va=\"center\",\n                 bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"black\", alpha=0.85))\n\n    savefig(os.path.join(OUT_DIR, fname_tsne))\n    plt.show()\n\nplot_latent_pca_tr(N_VIS=8000, use_noisy=True)\nplot_latent_umap_or_tsne(N_VIS=8000, use_noisy=True)\n\ndef sample_from_prior(n=30, seed=SEED, fname=\"07_generated_prior.png\"):\n    z = tf.random.normal(shape=(n, LATENT_DIM), seed=seed, dtype=tf.float32)\n    x_gen = decoder(tf.cast(z, tf.float32), training=False).numpy()\n\n    cols = 10\n    rows = int(math.ceil(n/cols))\n    plt.figure(figsize=(cols*1.2, rows*1.2))\n    for i in range(n):\n        ax = plt.subplot(rows, cols, i+1)\n        plt.imshow(x_gen[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n    plt.suptitle(\"Generated Samples (Prior ~ N(0,1))\", y=1.02)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\nsample_from_prior(30)\n\ndef latent_interpolation(steps=12, seed=SEED, fname=\"08_latent_interpolation.png\"):\n    rng = np.random.default_rng(seed)\n    i1, i2 = rng.integers(0, len(x_test), size=2)\n\n    xA = x_test_noisy[i1:i1+1]\n    xB = x_test_noisy[i2:i2+1]\n\n    zA_mean, _, _ = encoder(xA, training=False)\n    zB_mean, _, _ = encoder(xB, training=False)\n\n    alphas = np.linspace(0, 1, steps).astype(\"float32\")\n    z_interp = tf.concat([(1-a)*zA_mean + a*zB_mean for a in alphas], axis=0)\n\n    x_interp = decoder(z_interp, training=False).numpy()\n\n    plt.figure(figsize=(steps*1.2, 1.7))\n    for i in range(steps):\n        ax = plt.subplot(1, steps, i+1)\n        plt.imshow(x_interp[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n    plt.suptitle(f\"Latent Interpolation (zA → zB) | i1={i1}, i2={i2}\", y=1.15)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n    return int(i1), int(i2)\n\ni1, i2 = latent_interpolation()\n\ndef title_panel_denoising(n=6, fname=\"A_title_denoising.png\"):\n    idx = np.random.default_rng(SEED).choice(len(x_test), n, replace=False)\n    xN = tf.gather(x_test_noisy, idx)\n    xC = tf.gather(x_test, idx)\n    _, _, z = encoder(xN, training=False)\n    xR = decoder(z, training=False)\n\n    plt.figure(figsize=(n*1.5, 4))\n    for i in range(n):\n        plt.subplot(3, n, i+1)\n        plt.imshow(xN[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: plt.ylabel(\"Noisy\", fontsize=12)\n\n        plt.subplot(3, n, i+1+n)\n        plt.imshow(xR[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: plt.ylabel(\"VAE\", fontsize=12)\n\n        plt.subplot(3, n, i+1+2*n)\n        plt.imshow(xC[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n        if i == 0: plt.ylabel(\"Clean\", fontsize=12)\n\n    plt.suptitle(\"VAE Denoising (Fashion-MNIST)\", fontsize=18, y=1.05)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\ndef title_panel_representation(fname=\"B_title_representation_learning.png\", N=4000):\n    z_mean, _, _ = encoder(x_test[:N], training=False)\n    z_mean = z_mean.numpy()\n\n    pca = PCA(n_components=2, random_state=SEED)\n    z2 = pca.fit_transform(z_mean)\n\n    plt.figure(figsize=(6.5,6.0))\n    sc = plt.scatter(z2[:,0], z2[:,1], c=y_test[:N], s=5, alpha=0.7)\n    plt.colorbar(sc, ticks=range(10))\n    plt.title(\"Representation Learning\\nLatent Space (PCA)\", fontsize=16)\n    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\ndef title_panel_generation(n=20, fname=\"C_title_generation.png\"):\n    z = tf.random.normal((n, LATENT_DIM), seed=SEED, dtype=tf.float32)\n    x_gen = decoder(z, training=False).numpy()\n\n    cols = 10\n    rows = int(np.ceil(n / cols))\n    plt.figure(figsize=(cols*1.3, rows*1.3))\n    for i in range(n):\n        plt.subplot(rows, cols, i+1)\n        plt.imshow(x_gen[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n\n    plt.suptitle(\"Representation Generation\\nz ~ N(0,1)\", fontsize=18, y=1.05)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\ndef title_panel_interpolation(steps=10, fname=\"D_title_interpolation.png\"):\n    i1, i2 = np.random.default_rng(SEED).choice(len(x_test), 2, replace=False)\n\n    zA_mean, _, _ = encoder(x_test_noisy[i1:i1+1], training=False)\n    zB_mean, _, _ = encoder(x_test_noisy[i2:i2+1], training=False)\n\n    alphas = np.linspace(0, 1, steps).astype(\"float32\")\n    z_interp = tf.concat([(1-a)*zA_mean + a*zB_mean for a in alphas], axis=0)\n    x_interp = decoder(z_interp, training=False).numpy()\n\n    plt.figure(figsize=(steps*1.3, 2.0))\n    for i in range(steps):\n        plt.subplot(1, steps, i+1)\n        plt.imshow(x_interp[i,:,:,0], cmap=\"gray\"); plt.axis(\"off\")\n\n    plt.suptitle(\"Latent Interpolation (zA → zB)\", fontsize=16, y=1.15)\n    plt.tight_layout()\n    savefig(os.path.join(OUT_DIR, fname))\n    plt.show()\n\ntitle_panel_denoising()\ntitle_panel_representation()\ntitle_panel_generation()\ntitle_panel_interpolation()\n\nprint(\"\\nKaydedilen dosyalar:)\nfor fn in sorted(os.listdir(OUT_DIR)):\n    print(\"-\", fn)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}